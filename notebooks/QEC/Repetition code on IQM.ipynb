{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77c87f80",
   "metadata": {},
   "source": [
    "# Quantum Error Correction with the Repetition Code\n",
    "\n",
    "The notebook follows a hands-on approach:\n",
    "\n",
    "- You will **build and run** repetition code circuits using Qiskit,  \n",
    "\n",
    "- **Analyze** syndrome patterns from real device data,  \n",
    "\n",
    "- **Implement** and use a **Minimum Weight Perfect Matching (MWPM)** decoder with PyMatching\n",
    "\n",
    "- **Simulate the repetition code threshold** efficiently using Stim \n",
    "\n",
    "This material was written and developed by **Moritz Lange**, **Vidar Petersson**, and **Mats Granath**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2caf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install stim pymatching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbadb03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit import transpile, ClassicalRegister, QuantumCircuit, QuantumRegister\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pymatching\n",
    "import stim\n",
    "from iqm.qiskit_iqm import IQMProvider\n",
    "from pathlib import Path\n",
    "from getpass import getpass\n",
    "import uuid\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d043a19b",
   "metadata": {},
   "source": [
    "## RepetitionCodeCircuit\n",
    "\n",
    "This class builds a **repetition code circuit**, a minimal example of a quantum error-correcting code.  \n",
    "It encodes a single logical qubit into `d` physical qubits and performs `T` rounds of stabilizer (syndrome) measurements to detect errors.\n",
    "\n",
    "**Overview:**\n",
    "- The circuit consists of `d` **code qubits** (holding the logical information) and `d−1` **measure qubits** used to measure parities between neighboring code qubits.  \n",
    "- Each **syndrome measurement round** entangles the code and measure qubits via CNOT gates, then measures the measure qubits to extract error information without collapsing the logical state.\n",
    "- After the final round, all code qubits are measured in the chosen basis (`Z` or `X`) to perform the logical readout and final syndrome extraction.\n",
    "\n",
    "**Parameters:**\n",
    "- `d`: number of code qubits (code distance).  \n",
    "- `T`: number of syndrome measurement rounds.  \n",
    "- `xbasis`: if `True`, encodes and measures in the X basis instead of Z.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4edc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RepetitionCodeCircuit:\n",
    "    \"\"\"RepetitionCodeCircuit class.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        d: int,\n",
    "        T: int,\n",
    "        xbasis: bool = False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Creates the circuits corresponding to a logical 0 (or logical +1, if xbasis=True)\n",
    "        using a repetition code.\n",
    "\n",
    "        Implementation of a distance d repetition code, implemented over\n",
    "        T syndrome measurement rounds.\n",
    "\n",
    "        Args:\n",
    "            d (int): Number of code qubits (and hence repetitions) used.\n",
    "            T (int): Number of rounds of measure-assisted syndrome measurement.\n",
    "            xbasis (bool): Whether to use the X basis to use for encoding (Z basis used by default).\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.n = d\n",
    "        self.d = d\n",
    "        self.T = 0\n",
    "\n",
    "        self.code_qubit = QuantumRegister(d, \"code_qubit\")\n",
    "        self.measure_qubit = QuantumRegister((d - 1), \"measure_qubit\")\n",
    "        self.qubit_registers = {\"code_qubit\", \"measure_qubit\"}\n",
    "\n",
    "        self.measure_bits = []\n",
    "        self.code_bit = ClassicalRegister(d, \"code_bit\")\n",
    "\n",
    "        self.circuit = QuantumCircuit(self.measure_qubit, self.code_qubit)\n",
    "\n",
    "        self._xbasis = xbasis\n",
    "\n",
    "        # state preparation\n",
    "        if self._xbasis:\n",
    "            self.circuit.h(self.code_qubit)\n",
    "\n",
    "        for _ in range(T - 1):\n",
    "            self.syndrome_measurement()\n",
    "\n",
    "        if T != 0:\n",
    "            self.syndrome_measurement()\n",
    "            self.readout()\n",
    "\n",
    "    def syndrome_measurement(self):\n",
    "        \"\"\"Application of a syndrome measurement round.\n",
    "        \"\"\"\n",
    "\n",
    "        self.measure_bits.append(ClassicalRegister((self.d - 1), \"round_\" + str(self.T) + \"_measure_bit\"))\n",
    "\n",
    "        self.circuit.add_register(self.measure_bits[-1])\n",
    "\n",
    "        # entangling gates\n",
    "        self.circuit.barrier()\n",
    "        if self._xbasis:\n",
    "            self.circuit.h(self.measure_qubit)\n",
    "        for j in range(self.d - 1):\n",
    "            if self._xbasis:\n",
    "                self.circuit.cx(self.measure_qubit[j], self.code_qubit[j])\n",
    "            else:\n",
    "                self.circuit.cx(self.code_qubit[j], self.measure_qubit[j])\n",
    "        for j in range(self.d - 1):\n",
    "            if self._xbasis:\n",
    "                self.circuit.cx(self.measure_qubit[j], self.code_qubit[j + 1])\n",
    "            else:\n",
    "                self.circuit.cx(self.code_qubit[j + 1], self.measure_qubit[j])\n",
    "        if self._xbasis:\n",
    "            self.circuit.h(self.measure_qubit)\n",
    "        # measurement\n",
    "        self.circuit.barrier()\n",
    "        for j in range(self.d - 1):\n",
    "            self.circuit.measure(self.measure_qubit[j], self.measure_bits[self.T][j])\n",
    "\n",
    "        self.T += 1\n",
    "\n",
    "\n",
    "    def readout(self):\n",
    "        \"\"\"\n",
    "        Readout of all code qubits, which corresponds to a logical measurement\n",
    "        as well as allowing for a measurement of the syndrome to be inferred.\n",
    "        \"\"\"\n",
    "        if self._xbasis:\n",
    "            self.circuit.h(self.code_qubit)\n",
    "        self.circuit.add_register(self.code_bit)\n",
    "        self.circuit.measure(self.code_qubit, self.code_bit)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5177a6cc",
   "metadata": {},
   "source": [
    "## Task: Explore Basis Choice in the Repetition Code\n",
    "\n",
    "This task demonstrates how the choice of encoding basis affects the structure of the repetition code circuit.  \n",
    "A distance-3 code is used with two rounds of syndrome measurements. When `xbasis=True`, the logical qubit is encoded in the X basis, protecting against **phase-flip errors**.  \n",
    "When `xbasis=False`, the code is encoded in the Z basis, protecting against **bit-flip errors**.\n",
    "\n",
    "**Your task:**\n",
    "- Switch between `xbasis=True` and `xbasis=False`.  \n",
    "- Observe how the pattern of CNOT gates changes (who controls whom).  \n",
    "- Identify how the measurement basis and the type of stabilizers differ between the two cases.  \n",
    "- Think about why the X-basis version protects against phase errors while the Z-basis version protects against bit-flip errors.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6130662",
   "metadata": {},
   "outputs": [],
   "source": [
    "d, d_t = 3, 2\n",
    "circuit_class_instance = RepetitionCodeCircuit(d, d_t, xbasis=False)\n",
    "circuit = circuit_class_instance.circuit\n",
    "circuit.draw(output=\"mpl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90caf08c",
   "metadata": {},
   "source": [
    "## Connecting and Transpiling the Circuit for Hardware Execution\n",
    "\n",
    "This code connects to the **IQM Resonance** platform, selects a real quantum processor, and transpiles the repetition code circuit so it can be executed on that device.\n",
    "\n",
    "**Step-by-step explanation:**\n",
    "\n",
    "1. **Authenticate and connect to IQM**  \n",
    "   The script checks for an existing authentication token (`token.txt`).  \n",
    "   If no token is found, it prompts you to enter the access token generated from the IQM Resonance dashboard.  \n",
    "   The token is stored locally and used to authenticate future connections.  \n",
    "   After authentication, an **IQMProvider** instance is created and used to connect to the selected backend, here **`garnet`**.\n",
    "\n",
    "2. **Select the backend**  \n",
    "   The provider connects to the specified backend URL (`https://cocos.resonance.meetiqm.com/garnet`) and loads the corresponding hardware configuration.  \n",
    "   This backend represents a real superconducting quantum processor of IQM.\n",
    "\n",
    "3. **Transpile the circuit**  \n",
    "   The `transpile()` function adapts the repetition code circuit to the constraints of the selected IQM backend:\n",
    "   - **`backend=backend`** ensures the circuit uses the correct gate set and qubit connectivity.  \n",
    "   - **`initial_layout=layout`** (optional) specifies which physical qubits to use for reproducibility.  \n",
    "   - **`routing_method=\"none\"`** disables automatic SWAP insertion, keeping the logical qubit mapping intact.  \n",
    "   - **`optimization_level=1`** performs light optimization without altering the circuit structure.  \n",
    "   - **`seed_transpiler=42`** makes the transpilation deterministic and repeatable.\n",
    "\n",
    "4. **Visualize the transpiled circuit**  \n",
    "   The final hardware-mapped circuit is displayed using  \n",
    "   `draw(output=\"mpl\", idle_wires=False)`  \n",
    "   This shows the actual physical qubit layout and gate mapping while hiding unused qubits for clarity.\n",
    "\n",
    "After these steps, the repetition code circuit is ready for execution on the selected IQM device.\n",
    "\n",
    "**Note:**  \n",
    "The transpiler or backend may rename registers internally (for example, using names like `ancilla` or `q` instead of `measure_qubit`).  \n",
    "Don’t worry about the exact naming, simply identify the **measurement qubits** as those that are actually measured in each round of the circuit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45aa3cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_file = Path('token.txt')\n",
    "\n",
    "if not token_file.exists():\n",
    "    token = \"\"\n",
    "    while token == \"\":\n",
    "        token = getpass(\"Please enter the token from that you generated from IQM resonance\")\n",
    "        token_file.write_text(token)\n",
    "else:\n",
    "    print(\"Reusing existing token.txt\")\n",
    "token = token_file.read_text()\n",
    "os.environ[\"IQM_TOKEN\"] = token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f6d360",
   "metadata": {},
   "outputs": [],
   "source": [
    "backend_name = 'garnet'\n",
    "provider = IQMProvider(url = \"https://cocos.resonance.meetiqm.com/\" + backend_name)\n",
    "backend = provider.get_backend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483cde28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpile the circuit for the target backend without routing swaps\n",
    "layout = None  # Set to fixed physical layout for reproducibility, if desired\n",
    "transpiled_circuit = transpile(\n",
    "            RepetitionCodeCircuit(d, d_t, xbasis=True).circuit,\n",
    "            backend=backend,\n",
    "            initial_layout=layout,\n",
    "            routing_method=\"none\",  # Disable SWAP-based routing\n",
    "            optimization_level=1,\n",
    "            seed_transpiler=42,\n",
    "        )\n",
    "transpiled_circuit.draw(output=\"mpl\", idle_wires=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70afa707",
   "metadata": {},
   "source": [
    "## Task: Understanding Basis Choice and IQM’s Native Gate Decomposition\n",
    "\n",
    "1. **Start in the Z basis.**  \n",
    "   Run and visualize the repetition code with `xbasis=False`.  \n",
    "   In the transpiled circuit, each logical **CNOT** appears as a native **CZ** sandwiched by **Hadamards on the target**, but IQM implements H as single-qubit via:  \n",
    "   - pre-CZ: `R(π/2, nπ/2)`  \n",
    "   These realize a Hadamard up to a global phase, which is why you see `R(θ, φ)` instead of `H`.\n",
    "\n",
    "2. **Verify the CNOT construction.**  \n",
    "   Explicitly check that $(I \\otimes H) \\, CZ \\, (I \\otimes H) = CNOT$.\n",
    "\n",
    "3. **Switch to the X basis.**  \n",
    "   Set `xbasis=True` and re-run the transpilation. \n",
    "   Compare the resulting native circuit to the Z-basis version you analyzed before. \n",
    "\n",
    "From now on, we'll work with the phase flip repetition code (X basis)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2816d75",
   "metadata": {},
   "source": [
    "## Sampling from an IQM device\n",
    "\n",
    "We now execute the transpiled repetition code circuit on the selected **IQM backend** using Qiskit’s IQM provider. The IQM backend is responsible for submitting the circuit to the hardware, running it, and collecting the measurement results.\n",
    "\n",
    "1. **Set the number of shots.**  \n",
    "   Each circuit is executed `shots` times on the device.\n",
    "\n",
    "2. **Submit the circuit.**  \n",
    "   The circuit is sent to the backend with `backend.run(...)`.  \n",
    "   The backend queues the execution and returns a job ID that can be used to later retrieve the job.\n",
    "   You can find your job_id on the IQM Resonance platform webpage under your account’s job history.\n",
    "3. **Retrieve the results.**  \n",
    "   Once the job has finished, the results can be accessed through the job ID.  \n",
    "   The backend returns bitstring counts and metadata.\n",
    "\n",
    "4. **Store the results.**  \n",
    "   The results are saved locally as a JSON file containing the job ID, code distance `d`, number of rounds `d_t` and number of shots.  \n",
    "   This provides a consistent record for later analysis.\n",
    "\n",
    "**Note:** Avoid calling backend.run([...]) too often! Each execution consumes part of your IQM runtime quota.  \n",
    "If you’ve already run a job, you can retrieve its results later instead of re-running the circuit.\n",
    ">\n",
    "python\n",
    "> job = backend.retrieve_job(job_id)\n",
    "\n",
    "> result = job.result()\n",
    ">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c0f383",
   "metadata": {},
   "outputs": [],
   "source": [
    "shots = 10_000\n",
    "# Each execution of the following line consumes part of your IQM runtime quota!\n",
    "# job = backend.run(transpiled_circuit, shots=shots)\n",
    "\n",
    "job = backend.retrieve_job(job_id)\n",
    "job_result = job.result()\n",
    "counts = job_result.get_counts()\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e84cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_filename_real_device = os.path.join(\n",
    "    \"./jobdata/\",\n",
    "    f\"{backend_name}_{job.job_id()}_d_{d}_d_t_{d_t}_shots_{shots}.json\"\n",
    ")\n",
    "os.makedirs(os.path.dirname(res_filename_real_device), exist_ok=True)\n",
    "\n",
    "def serialize(obj):\n",
    "    if isinstance(obj, uuid.UUID):\n",
    "        return str(obj)\n",
    "    raise TypeError(f\"Type {type(obj)} not serializable\")\n",
    "\n",
    "job_result = job.result().to_dict()\n",
    "with open(res_filename_real_device, \"w\") as f:\n",
    "    json.dump(job_result, f, default=serialize, indent=2)\n",
    "\n",
    "print(f\"Measurement saved as '{res_filename_real_device}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1923bb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(res_filename_real_device) as f:\n",
    "    data = json.load(f)\n",
    "counts = data['results'][0]['data']['counts']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59dbdc48",
   "metadata": {},
   "source": [
    "## Visualizing measurement outcomes\n",
    "\n",
    "Measurement results are grouped by the final data qubit states. Each subplot shows the distribution of syndrome outcomes for one data state: the x-axis lists syndrome bitstrings, and the y-axis (log scale) shows their counts. This reveals which syndrome patterns dominate for each logical outcome.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35385754",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_counts = defaultdict(dict)\n",
    "for bitstring, count in counts.items():\n",
    "    data, *syndrome = bitstring.split()\n",
    "    grouped_counts[data][\" \".join(syndrome)] = count\n",
    "\n",
    "n_groups = len(grouped_counts)\n",
    "n_cols = math.ceil(math.sqrt(n_groups))\n",
    "n_rows = math.ceil(n_groups / n_cols)\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(4 * n_cols, 4 * n_rows), sharey=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax, (data_state, subcounts) in zip(axes, sorted(grouped_counts.items())):\n",
    "    keys = sorted(subcounts.keys())\n",
    "    values = [subcounts[k] for k in keys]\n",
    "\n",
    "    ax.bar(range(len(keys)), values)\n",
    "    ax.set_xticks(range(len(keys)))\n",
    "    ax.set_xticklabels(keys, rotation=45, ha='right')\n",
    "    ax.set_title(f\"Data qubits: {data_state}\")\n",
    "    ax.set_xlabel(\"Syndrome outcomes\")\n",
    "    ax.set_yscale('log')\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.4)\n",
    "\n",
    "for ax in axes[len(grouped_counts):]:\n",
    "    ax.axis('off')\n",
    "\n",
    "axes[0].set_ylabel(\"Counts\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f149ea",
   "metadata": {},
   "source": [
    "## Task: Understanding Syndrome Distributions\n",
    "\n",
    "0. **Noiseless execution.**  \n",
    "   Think about the circuit we implemented. In an ideal world without any noise, what outcome(s) would you expect? \n",
    "   Next, focus on the data above:\n",
    "\n",
    "1. **Identify the dominant syndrome.**  \n",
    "   For each logical data state, find the syndrome outcome with the highest count.  \n",
    "   Does this dominant syndrome make sense given what you expect for that logical state?\n",
    "\n",
    "2. **Interpret deviations.**  \n",
    "   Look at the remaining, less frequent syndrome outcomes.  \n",
    "   What might these correspond to - single-qubit phase flips, measurement errors, or other noise events introduced by the circuit?\n",
    "\n",
    "3. **Relate to decoding.**  \n",
    "   Discuss how a decoder could use these syndrome patterns to infer the most likely logical state.  \n",
    "   Which of the bins will go undetected and lead to a logical error?\n",
    "\n",
    "**Hint 1:**  \n",
    "Because we don’t reset the measure qubits after measurement, a persistent error on a data qubit will cause the corresponding measure to *alternate between 1 and 0* in subsequent rounds.\n",
    "\n",
    "**Hint 2:**  \n",
    "Qiskit lists classical registers in *reverse* order of how they were added.  \n",
    "Within each register, bits appear from most- to least-significant.  \n",
    "\n",
    "So for an outcome like `100 01 00` (with `d=3`, `T=2`):  \n",
    "- `100` → data qubit readout (added last, shown first)  \n",
    "- `01` → measure bits from the **last** syndrome round, where the **leftmost** bit is the **last measure qubit**  \n",
    "- `00` → measure bits from the **first** round  \n",
    "\n",
    "You can verify this order by checking `circuit.cregs`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b148a49",
   "metadata": {},
   "source": [
    "## From Syndrome Patterns to Decoding\n",
    "\n",
    "In the previous task, you examined how specific syndromes correspond to logical states and how noise alters these distributions.  \n",
    "That exercise is the **core idea behind decoding**: given a noisy measurement record (the syndrome), infer the most probable underlying logical state or error configuration that caused it.\n",
    "\n",
    "Loosely speaking, the **decoding problem** in quantum error correction is to determine the most likely set of physical errors that explain the measured outcomes.  \n",
    "An ideal decoder assigns a correction minimizing the probability of a logical error.\n",
    "\n",
    "We now move from qualitative reasoning about syndrome patterns to a quantitative decoding framework.  \n",
    "In the next section, you’ll implement a **Minimum Weight Perfect Matching (MWPM)** decoder, which formalizes this inference process.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## MWPM Decoder\n",
    "\n",
    "The `MWPMDecoder` class implements a **Minimum Weight Perfect Matching (MWPM)** decoder for the repetition code. It uses the **PyMatching** library ([Higgott & Gidney, *PyMatching v2*, 2022](https://github.com/oscarhiggott/PyMatching)) to decode detection events obtained from either hardware or simulator runs. The edges in the matching graph correspond to probabilities of error events, directly obtained from the detection events via the *p_ij method* ([Spitz et al.](https://arxiv.org/abs/1712.02360))\n",
    "\n",
    "1. **Initialization**  \n",
    "   The decoder loads the measurement results, extracting the code and measure qubit readouts. The measurement outcomes are then converted to the form expected if measure qubits were reset after each round.\n",
    "\n",
    "2. **Detection event extraction**  \n",
    "   The syndrome time series is converted into *detection events* - binary indicators marking changes between consecutive measurement rounds. These correspond to nodes in the decoding graph.\n",
    "\n",
    "3. **Logical outcome mapping**  \n",
    "   Logical flips are determined by comparing the final data qubit state to the expected logical state.\n",
    "\n",
    "4. **Correlation-based edge weights**  \n",
    "   A full correlation matrix between detection events is computed using the p_ij method. Edge weights are set as `-log(p_ij)`, linking detection nodes both **spatially** (within a round) and **temporally** (across rounds).\n",
    "\n",
    "5. **Graph construction and decoding**  \n",
    "   The matching graph is built with PyMatching, containing both space-like and time-like edges. MWPM then identifies the most likely set of error chains consistent with observed syndromes.\n",
    "\n",
    "6. **Performance evaluation**  \n",
    "   The decoder compares predicted and actual logical outcomes to estimate logical accuracy and its statistical uncertainty.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ea81ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MWPMDecoder:\n",
    "    \"\"\"\n",
    "    Minimum Weight Perfect Matching (MWPM) decoder for rep code syndrome data.\n",
    "\n",
    "    This decoder uses PyMatching to construct a matching graph based on observed\n",
    "    detection events from a quantum circuit, and predicts logical errors\n",
    "    by decoding these using MWPM. Weights can be computed from pairwise detection correlations,\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, distance, t, counts, shots) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the MWPMDecoder.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        args : Args\n",
    "            Configuration object containing code parameters and backend settings.\n",
    "        \"\"\"\n",
    "        self.distance = distance\n",
    "        self.n_measures = distance - 1\n",
    "        self.t = t\n",
    "        self.matcher = pymatching.Matching()\n",
    "        self.shots = shots\n",
    "        self.counts = counts\n",
    "        self._load_job_data()\n",
    "\n",
    "    def _load_job_data(self) -> None:\n",
    "        \"\"\"\n",
    "        Load syndrome and logical flip data.\n",
    "        \"\"\"\n",
    "        syndromes, final_state = [], []\n",
    "        for bitstring, freq in self.counts.items():\n",
    "            bits = bitstring.replace(\" \", \"\")\n",
    "            final = [b == \"1\" for b in bits[:self.distance]]\n",
    "            syndrome = [b == \"1\" for b in bits[self.distance:]]\n",
    "            syndromes.extend([syndrome] * freq)\n",
    "            # t...0\n",
    "            final_state.extend([final] * freq)\n",
    "        final_state = np.array(final_state, dtype=np.uint8)\n",
    "        syndromes = np.array(syndromes, dtype=np.uint8)\n",
    "        # reverse time order to start from round 0:\n",
    "        syndromes = syndromes[:, ::-1]\n",
    "        # no reset used, so take diff in subsequent measurements\n",
    "        # reshape to (n_shots, n_rounds, n_anc)\n",
    "        syndromes_reshaped = syndromes.reshape(-1, self.t, self.n_measures)\n",
    "\n",
    "        # compute diff along time axis (rounds)\n",
    "        diff = (syndromes_reshaped[:, 1:, :] != syndromes_reshaped[:, :-1, :]).astype(np.uint8)\n",
    "\n",
    "        # prepend first measurement\n",
    "        first = syndromes_reshaped[:, :1, :].astype(np.uint8)\n",
    "        syndrome = np.concatenate([first, diff], axis=1)\n",
    "\n",
    "        # flatten back\n",
    "        syndrome = syndrome.reshape(syndromes.shape)\n",
    "\n",
    "        # Reverse bit order back to match IBM's convention\n",
    "        syndrome = syndrome[:, ::-1]\n",
    "\n",
    "        initial_syndrome = np.full((self.shots, self.n_measures), int(0), dtype=np.uint8)\n",
    "\n",
    "        final_syndrome = final_state[:, :-1] ^ final_state[:, 1:]\n",
    "        syndrome_matrix = np.concatenate([initial_syndrome, syndrome, final_syndrome], axis=1)\n",
    "        T = syndrome_matrix.shape[1] // self.n_measures\n",
    "        reshaped = syndrome_matrix.reshape(-1, T, self.n_measures)\n",
    "        flips = np.diff(reshaped, axis=1).astype(bool)\n",
    "        self.detections = flips.reshape(flips.shape[0], -1)\n",
    "\n",
    "        # get equivalence class defined by last data qubit\n",
    "        self.logical_flips = (final_state[:, 0] == 1)\n",
    "\n",
    "    def _error_correlation_matrix_full(self) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Compute the full correlation matrix from the observed detections.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pij_matrix : np.ndarray\n",
    "            A symmetric matrix of error-pairing probabilities between detector events.\n",
    "        \"\"\"\n",
    "        x = self.detections.astype(np.float64)  # shape (shots, N)\n",
    "\n",
    "        # Compute means\n",
    "        mean_i = x.mean(axis=0)  # shape (N,)\n",
    "        mean_ij = (x.T @ x) / x.shape[0]  # shape (N, N)\n",
    "\n",
    "        # Numerator and denominator\n",
    "        numerator = mean_ij - np.outer(mean_i, mean_i)\n",
    "        denominator = 1 - 2 * mean_i[:, None] - 2 * mean_i[None, :] + 4 * mean_ij\n",
    "\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            sqrt_term = np.sqrt(1 - 4 * numerator / denominator)\n",
    "            pij = 0.5 - 0.5 * sqrt_term\n",
    "\n",
    "        pij = np.where(np.isfinite(pij), pij, 0.0)  # Replace NaNs and infs with 0.0\n",
    "        np.fill_diagonal(pij, 0.0)  # set diagonal to 0 for clarity\n",
    "\n",
    "        return pij\n",
    "\n",
    "    \n",
    "    def _get_edges(self) -> None:\n",
    "        \"\"\"\n",
    "        Build the matching graph with edges weighted according to the selected weight scheme.\n",
    "\n",
    "        Constructs both space-like (within a time slice) and time-like (between time slices) edges.\n",
    "        Edge weights are derived from the negative log of correlation coefficients.\n",
    "        \"\"\"\n",
    "        row_len = self.distance - 1\n",
    "        error_correlation = self._error_correlation_matrix_full()\n",
    "            \n",
    "        error_correlation[error_correlation <= 0] = 1e-7  # Avoid log(0) or negative weights\n",
    "            \n",
    "        weights = -np.log(error_correlation)\n",
    "\n",
    "        # Add space-like edges (horizontal, within each time slice)\n",
    "        for t_index in range(self.t + 1):\n",
    "            row_start = t_index * row_len\n",
    "            row_end = row_start + row_len\n",
    "\n",
    "            for i in range(row_start, row_end - 1):\n",
    "                self.matcher.add_edge(\n",
    "                    i, i + 1,\n",
    "                    weight=weights[i][i + 1],\n",
    "                    fault_ids={i % row_len + 1},\n",
    "                    merge_strategy='replace'\n",
    "                )\n",
    "\n",
    "            self.matcher.add_boundary_edge(\n",
    "                row_start,\n",
    "                weight=weights[row_start][row_start + 1],\n",
    "                fault_ids={0},\n",
    "                merge_strategy='replace'\n",
    "            )\n",
    "\n",
    "            self.matcher.add_boundary_edge(\n",
    "                row_end - 1,\n",
    "                weight=weights[row_end - 2][row_end - 1],\n",
    "                fault_ids={row_len},\n",
    "                merge_strategy='replace'\n",
    "            )\n",
    "        # Add time-like edges (vertical, across time slices)\n",
    "        for t_index in range(self.t):\n",
    "            for offset in range(row_len):\n",
    "                i = t_index * row_len + offset\n",
    "                j = i + row_len\n",
    "                self.matcher.add_edge(\n",
    "                    i, j,\n",
    "                    weight=weights[i][j],\n",
    "                    merge_strategy='replace'\n",
    "                )\n",
    "\n",
    "    def _evaluate_predictions(self) -> float:\n",
    "        \"\"\"\n",
    "        Evaluate decoder accuracy using.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        logical_accuracy : float\n",
    "            Logical decoding accuracy, including both trivial and non-trivial shots.\n",
    "        \"\"\"\n",
    "\n",
    "        # Filter out trivial syndromes\n",
    "        nontrivial = np.any(self.detections, axis=1)\n",
    "        detections_nt = self.detections[nontrivial]\n",
    "        flips_nt = self.logical_flips[nontrivial]\n",
    "        # Decode predictions using MWPM\n",
    "        predictions = self.matcher.decode_batch(detections_nt)\n",
    "        predicted = predictions[:, 0]\n",
    "        correct = np.sum(flips_nt == predicted)\n",
    "        trivial_count = np.sum(~nontrivial)\n",
    "\n",
    "        logical_accuracy = (correct + trivial_count) / self.detections.shape[0]\n",
    "        logical_accuracy_err = np.sqrt(logical_accuracy * (1- logical_accuracy\n",
    "                                                           ) / self.detections.shape[0])\n",
    "\n",
    "        return logical_accuracy, logical_accuracy_err, trivial_count\n",
    "\n",
    "    def decode(self) -> float:\n",
    "        \"\"\"\n",
    "        Full decoding pipeline: load data, construct the graph, run decoding, and return accuracy.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        logical_accuracy : float\n",
    "            Logical accuracy on the validation set.\n",
    "        \"\"\"\n",
    "\n",
    "        self._get_edges()\n",
    "        pdet_mean = self.detections.mean()\n",
    "        logical_accuracy, logical_accuracy_err, trivial_count = self._evaluate_predictions()\n",
    "        return logical_accuracy, logical_accuracy_err, pdet_mean, trivial_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d551c338",
   "metadata": {},
   "source": [
    "## Task: Investigating Error Correction by Increasing Code Distance\n",
    "\n",
    "In this task, you will run the repetition code circuit on an IQM backend for **code distances 3 and 5**.  \n",
    "The goal is to see whether increasing the code distance improves the **logical accuracy** of the encoded qubit.\n",
    "1. **Run both circuits.**  \n",
    "   Execute the repetition code for `d=5` on the same IQM backend using the same number of rounds and shots.  \n",
    "   Save the resulting measurement data.\n",
    "\n",
    "2. **Decode each dataset.**  \n",
    "   Apply the `MWPMDecoder` to the results from both distances.  \n",
    "   Compute the logical accuracy or failure rate for each code distance.\n",
    "\n",
    "3. **Compare the outcomes.**  \n",
    "   Examine how the logical failure rate changes when increasing the code distance from 3 to 5.  \n",
    "   Does the larger code show better suppression of errors, as expected from quantum error correction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031c4229",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = MWPMDecoder(distance=d, t=d_t, counts = counts, shots = shots)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a7bd77",
   "metadata": {},
   "source": [
    "## Threshold Estimation with Stim\n",
    "\n",
    "Estimating the **logical error threshold** requires running the repetition code at many noise levels and code distances to see where increasing distance begins to suppress logical errors.  \n",
    "Doing this directly with Qiskit, either on simulators or real hardware, would be prohibitively expensive, since each data point requires thousands of circuit runs.\n",
    "\n",
    "To make this feasible, we switch to **Stim** (Gidney, 2021) [@gidney2021stim](https://doi.org/10.22331/q-2021-07-06-497), a high-performance stabilizer simulator.  \n",
    "Stim models the circuits but operates directly in the stabilizer formalism and tracks *detection events* rather than full quantum states.  \n",
    "This makes it orders of magnitude faster and allows simulation of millions of shots per second.\n",
    "\n",
    "**Circuit generation**  \n",
    "We use the `stim.Circuit.generated(...)` method to define a repetition-code memory experiment. The parameters include code distance `d`, number of rounds `rounds=d`, and a noise rate `noise` which sets depolarization after Clifford gates, flip probability after resets, flip probability before measurement, and data-qubit depolarization before each round. This produces a stabilizer circuit that models repeated syndrome extraction under **circuit-level noise**.  \n",
    "\n",
    "**Logical error counting & decoding**  \n",
    "We define a `count_logical_errors(circuit, num_shots)` routine which  \n",
    "(1) compiles the circuit into a detector sampler via `circuit.compile_detector_sampler()`  \n",
    "(2) samples `num_shots` shots producing two outputs: `detection_events` (space–time patterns of syndrome flips) and `observable_flips` (whether the logical observable flipped)  \n",
    "(3) extracts the detector error model via `circuit.detector_error_model(decompose_errors=True)`  \n",
    "(4) builds a decoder graph with PyMatching (`pymatching.Matching.from_detector_error_model(...)`)  \n",
    "(5) decodes the detection events in batch (`matcher.decode_batch(detection_events)`)  \n",
    "and finally (6) counts how many decoded logical outcomes differ from the true flips, yielding the number of logical errors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab855000",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_logical_errors(circuit, num_shots):\n",
    "    sampler = circuit.compile_detector_sampler()\n",
    "    detection_events, observable_flips = sampler.sample(num_shots, separate_observables=True)\n",
    "\n",
    "    detector_error_model = circuit.detector_error_model(decompose_errors=True)\n",
    "    matcher = pymatching.Matching.from_detector_error_model(detector_error_model)\n",
    "    predictions = matcher.decode_batch(detection_events)\n",
    "\n",
    "    num_errors = (predictions != observable_flips).sum()\n",
    "    return num_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ff1846",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = 0.01\n",
    "circuit = stim.Circuit.generated(\n",
    "            \"repetition_code:memory\",\n",
    "            rounds=d,\n",
    "            distance=d,\n",
    "            after_clifford_depolarization=noise,\n",
    "            after_reset_flip_probability=noise,\n",
    "            before_measure_flip_probability=noise,\n",
    "            before_round_data_depolarization=noise)\n",
    "circuit.diagram('timeline-svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031a5626",
   "metadata": {},
   "source": [
    "## Task: Estimating the Logical Error Threshold\n",
    "\n",
    "In this task, you will use **Stim** and **PyMatching** to estimate the **logical error threshold** of the repetition code.\n",
    "\n",
    "1. **Vary the noise strength and code distance.**  \n",
    "   Run the logical error counting procedure (`count_logical_errors`) for multiple values of the physical noise rate, e.g. p = 0.001, ..., 0.15 and for several code distances d = 3, ... 21.\n",
    "\n",
    "2. **Compute logical error rates.**  \n",
    "   For each combination of (d, p), estimate the logical failure probability p_L using the number of logical errors returned by your decoding function.\n",
    "\n",
    "3. **Plot the threshold curve.**  \n",
    "   On a log-log plot, show p_L vs. p for each code distance d.  \n",
    "   The **threshold** is the crossing point of these curves - where increasing d begins to *reduce* the logical error rate.  \n",
    "\n",
    "4. **Interpretation.**  \n",
    "   - What approximate threshold value $ p_\\text{th} $ do you observe?  \n",
    "   - How does it compare to theoretical expectations for a phase-flip repetition code under circuit-level noise?  \n",
    "   - How does the slope below the threshold reflect the code’s scaling behavior (hint: what is the shortest chain of errors that leads to a logical error?)?\n",
    "\n",
    "This task connects the repetition code’s performance under noise to the concept of **fault tolerance**: below the threshold, increasing code size exponentially suppresses logical errors, while above it, error correction fails to keep up with noise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30624543",
   "metadata": {},
   "outputs": [],
   "source": [
    "noises = np.arange(0.001, 0.151, 0.01)\n",
    "N = 10_000\n",
    "ds = np.arange(3, 31, 4)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3,2))\n",
    "P_Ls = {}\n",
    "\n",
    "for d in ds:\n",
    "    P_L = []\n",
    "    for noise in noises:\n",
    "        circuit = stim.Circuit.generated(\n",
    "            \"repetition_code:memory\",\n",
    "            rounds=d,\n",
    "            distance=d,\n",
    "            after_clifford_depolarization=noise,\n",
    "            after_reset_flip_probability=noise,\n",
    "            before_measure_flip_probability=noise,\n",
    "            before_round_data_depolarization=noise)\n",
    "        #...#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
